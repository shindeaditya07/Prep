{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b1952af-1f2c-47d0-9fa8-d3722e7abfff",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\r\n",
    "Machine Learning (ML) is a branch of artificial intelligence (AI) that empowers computers to learn from data, enabling them to recognize patters,d predict outcoese, and classify data into clases.g\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b0ac55-996f-4c8f-8a9e-e522b3eec840",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "1. Handling Missing Data - Certain values absent from dataset, negatively affect model performance. Involves deleting rows, replacing null values with mean, median or mode.\n",
    "2. Data Normalisation & Standardisation - Techniques to scale data, such that features contribute equally to model's predictions. Rescaling data to [0,1] (normalisation), or transforming data to have mean 0 and standard deviation \n",
    "3. Data Splitting - Data is split into Training, Testing, Validation Data to evaluate performance and avoid overfitting. Training Set used for training the model, Validation Set used to hypertune parameters & validate model performance, Testing Set used to evaluate model performance after training. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f844dc22-abba-42c1-b0cb-d26d0d7dbced",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Feature Engineering is creating and selecting the most relevant features from raw data to improve the accuracy and effectiveness of a machine learning model.\n",
    "It consists of:\n",
    "1. Feature Selection - Identifying and selecting the most important features that contribute to the predictive power of the model.\n",
    "   a) Filter Methods - Based on statistical tests ot correlation metrics.\n",
    "   b) Wrapper Methods - Iteratively select features based on model performance.\n",
    "2. Feature Extraction - Creating new features from existing data to improve model accuracy.\n",
    "   a) Dimensionality Reduction - Principal Component Analysis (PCA) reduces number of features to avoid overfitting.\n",
    "   b) Transformation - Apply mathematical transformation to create new features.\n",
    "   c) Encoding Categorical Data - Converting categorical variables into numerical values using label encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dcbd1b1-e9fb-4e46-8af6-5b85c8c3f33e",
   "metadata": {},
   "source": [
    "## Types of Learning in ML include:\n",
    "1.\tSupervised Learning - Uses labeled data to train models that map inputs to outputs. \n",
    "    Eg: Regression and classification algorithms.\n",
    "2.\tUnsupervised Learning - Discovers patterns in unlabeled data, with applications in clustering, customer segmentation, and anomaly detection. \n",
    "    Eg: Clustering, Dimensionality reduction.\n",
    "3.\tReinforcement Learning - An agent learns to make decisions by performing actions in an environment to maximize the notion of cumulative reward. \n",
    "    Eg: Q-Learning.\n",
    "4.\tSemi-Supervised Learning - Combines a small amount of labeled data with a large amount of unlabeled data to improve learning.\n",
    "    Eg: Web content classification, fraud detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b6ab3-7c09-4f02-b4ec-825d8f36105b",
   "metadata": {},
   "source": [
    "## Supervised Learning\n",
    "Uses labeled data to train models that map inputs to outputs. Eg: Regression and classification algorithms.\n",
    "## Regression\n",
    "   Used to predict the dependent variable based on the values of the independent variables. 2 types:\n",
    "   a) Linear Regression - Models the relationship between a dependent variable and one or more independent variables with a linear equation.\n",
    "      Application – House price prediction.\n",
    "      Python Module: from sklearn.linear_model import LinearRegression\n",
    "   b) Polynomial Regression - Extends linear regression by modelling the relationship as an n-degree polynomial.\n",
    "      Application – Stock Price Prediction\n",
    "      Python Module: from sklearn.preprocessing import PolynomialFeatures                      \r",
    "                     from sklearn.linear_model import LinearRegression\n",
    "                     from sklearn.pipeline import make_pipeline\n",
    "\n",
    "   Evaluation Metrics in Regression\n",
    "   a) Mean Absolute Error (MAE) - Average of absolute difference between predicted and actual values.\n",
    "   b) Mean Squared Error (MSE) - Average of the squared differences between predicted and actual values.\n",
    "   c) Root Mean Squared Error (RMSE) - Square root of MSE, error is in same units as target variable.\n",
    "   d) R-squared - Measures how well regression model explains variance in target variable, given in percentagen\r\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "520bf318-74c1-4a4a-b258-43455433b19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter years of experience:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Salary:  50000.0\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "# Years of Experience vs Salary\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "X = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9]]) # Always in 2d form\n",
    "y = np.array([30000,35000,40000,45000,50000,55000,60000,65000,70000])\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X,y)\n",
    "\n",
    "def pred_model(experience):\n",
    "    exp_array = np.array([[experience]])\n",
    "    return model.predict(exp_array)[0]\n",
    "\n",
    "print(\"OUTPUT\")\n",
    "years = int(input(\"Enter years of experience: \"))\n",
    "\n",
    "pred_sal = pred_model(years)\n",
    "print(\"Expected Salary: \", pred_sal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "34ce8a2f-5815-40ea-bc26-896c9f695e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the years of experience:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted salary:  [35000.]\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Regression\n",
    "# Years of Experience vs Salary\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "X = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9]]) # Always in 2d form\n",
    "y = np.array([30000,35000,40000,45000,50000,55000,60000,65000,70000])\n",
    "\n",
    "deg = 2\n",
    "poly = PolynomialFeatures(deg)\n",
    "model = make_pipeline(poly, LinearRegression())\n",
    "model.fit(X,y)\n",
    "\n",
    "print(\"OUTPUT\")\n",
    "years = int(input(\"Enter the years of experience: \"))\n",
    "years_reshaped = np.array([[years]])\n",
    "pred_sal = model.predict(years_reshaped)\n",
    "\n",
    "print(\"Predicted salary: \", pred_sal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e80ee55-d54d-45e6-bef7-7afa264d8923",
   "metadata": {},
   "source": [
    "## Classification\n",
    "   Process where a model is trained to categorize data into predefined groups or classes. 3 types:\n",
    "   a) Logistic Regression - Models the probability of a binary outcome based on one or more predictor variables.\n",
    "      Application – Medical diagnosis\n",
    "      Python Module: from sklearn.linear_model import LogisticRegression\n",
    "   b) Support Vector Machines - Finds the hyperplane which best separates the classes in the  feature space.\n",
    "      Application – Image classification\n",
    "      Python Module: from sklearn.svm import SVC\n",
    "   c) Decision Trees - Splits the data into subsets based on the value of input features, forming a tree-like structure.\n",
    "      Application – Customer segmentation\n",
    "      Python Module: from sklearn.tree import DecisionTreeClassifier\n",
    "   d) K-Nearest Neighbour (KNN) - Classifies data points based on the majority class of their nearest neighbors in the feature space.\n",
    "      Application – Image recognition   \n",
    "      Python Module: from sklearneighborsle imporKNeighborsstClassifier (for classification)\n",
    "               from sklearn.neighbors import KNeighborsRegressor (for regression)\n",
    "\n",
    "   Evaluation Metrics for Classification\n",
    "   a) Accuracy - Proportion of correctly predicted instances out of total predicted instances.\n",
    "   b) Precision - Proportion of true positive predictions among all (true and false positives) positive predictions.\n",
    "   c) Recall - Proportion of true positive predictions among all actual (true +ives and false    -ives) positive predictions.\n",
    "   d) F1-Score - Harmonic mean of precision and recall, it is a single metric that balances both.\n",
    "   e) ROC-AUC - Stands for \"Reciever Operating Characteristic - Area Under Curve\", represents model's ability to distinguish between classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9afd5e86-f06e-46f9-8dce-b63261ae0931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter number of hours studied: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "#Pass or Fail based on Number of Hours Studied\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = np.array([[1],[2],[3],[4],[5],[6],[7],[8],[9]])\n",
    "y = np.array([0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "inp = float(input(\"Enter number of hours studied:\"))\n",
    "hours = np.array([[inp]])\n",
    "prediction = model.predict(hours)\n",
    "print(f\"{'Pass' if prediction[0] ==1 else 'Fail'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0150b14-c890-45bd-9b02-33341bca6aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter customer age:  23\n",
      "Enter salary of customer:  40000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cannot buy\n"
     ]
    }
   ],
   "source": [
    "#K-Nearest Neighbours\n",
    "#Will customer buy a product based on age and salary\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "X = np.array([[22,25000],[25,30000],[27,40000],[30,50000],[40,80000],[45,110000],\n",
    "              [50,150000],[55,200000],[60,250000]]) #[Age, Salary]\n",
    "y = np.array([0,0,0,0,1,1,1,1,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "age = float(input(\"Enter customer age: \"))\n",
    "salary = float(input(\"Enter salary of customer: \"))\n",
    "customer = np.array([[age,salary]])\n",
    "\n",
    "prediction = knn.predict(customer)\n",
    "print(f\"{'Can buy' if prediction[0] == 1 else 'Cannot buy'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "14d6045c-6ae8-42ef-b7bd-445b008f1cc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter age:  21\n",
      "Enter bmi:  31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diabetic\n"
     ]
    }
   ],
   "source": [
    "#Support Vector Machines\n",
    "#Does person have diabetes\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = np.array([[25,18.5],[30,22.5],[35,24.0],[40,26.5],[45,28.0],[50,30.5],\n",
    "              [55,32.0],[60,34.5],[65,36],[70,38.5]]) #[Age, BMI]\n",
    "y = np.array([0,0,0,0,1,1,1,1,1,1])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2, random_state = 42)\n",
    "\n",
    "svm_model = SVC(kernel = 'linear')\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred = svm_model.predict(X_test)\n",
    "\n",
    "age = float(input(\"Enter age: \"))\n",
    "bmi = float(input(\"Enter bmi: \"))\n",
    "health = np.array([[age,salary]])\n",
    "\n",
    "prediction = svm_model.predict(health)\n",
    "print(f\"{'Diabetic' if prediction[0] == 1 else 'Not diabetic'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aacae7e-dcca-4d49-864a-ab21fc30b802",
   "metadata": {},
   "source": [
    "## Unsupervised Learning\n",
    "Discovers patterns in unlabeled data, with applications in clustering, customer segmentation, and anomaly detection. Eg: Clustering, Dimensionality reduction.\n",
    "## Clustering:\n",
    "   Grouping of a set of objects in the same group (or cluster) in such a way that objects in the same group are more similar to each other than those in other groups.\n",
    "   a) K-Means Clustering - Divides data into k distinct, non-overlapping groups based on feature similarity.\n",
    "      Application - Customer segmentation in marketing, grouping similar items.\n",
    "      Python Module - from sklearn.cluster import KMeans\n",
    "   b) Hierarchical Clustering - Creates a tree-like structure (dendrogram) to group data points based on their similarity.\n",
    "      Application - Gene Expression Analysis.\n",
    "      Python Module - from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "   c) DBSCAN - Clusters data based on density of data points in a region.\n",
    "      Application - Identify clusters in spatial data, noise detection, anomaly detection.\n",
    "      Python Module - from sklearn.cluster import DBSCAN\n",
    "\n",
    "   Evaluation Metrics:\n",
    "   a) Silhouette Score - Measures how similar a data point is to its own cluster compared to other clusters. Range [-1,1] where Close to 1 - Well matched to own cluster, Close to 0 - Very close to boundary between 2 neighbouring clusters, Close to -1 - Might be assigned to wrong cluster.\n",
    "   b) Davies-Bouldin Index - Evaluates average similarity ratio of each cluster with cluster most similar to it. Range [0, inf] where lower values indicate better clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "416bd1b5-41f7-4b7c-b0fb-3b54742dba59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\New folder\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "C:\\Software\\Anaconda\\New folder\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "X coordinate:  2\n",
      "Y coordinate:  2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 2,2 lies in cluster 2\n"
     ]
    }
   ],
   "source": [
    "#Clustering of data points using KMeans clustering\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "X = ([[1,2],[1,4],[1,0],[4,2],[4,4],[4,0]])\n",
    "\n",
    "kmeans = KMeans(n_clusters = 4, random_state = 42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "x = int(input(\"X coordinate: \"))\n",
    "y = int(input(\"Y coordinate: \"))\n",
    "data = np.array([[x,y]])\n",
    "\n",
    "clusters = kmeans.predict(data)\n",
    "print(f\"Point {x},{y} lies in cluster {clusters[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5de5d94c-92b1-469c-9a25-4dc39f064a55",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "X coordinate:  5\n",
      "Y coordinate:  6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Point 5,6 added to dataset, view dendrogram too see cluster hierarchy\n"
     ]
    }
   ],
   "source": [
    "#Clustering of data points using Hierarchical clustering\n",
    "import numpy as np\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X = ([[1,2],[1,4],[1,0],[4,2],[4,4],[4,0]])\n",
    "\n",
    "x = int(input(\"X coordinate: \"))\n",
    "y = int(input(\"Y coordinate: \"))\n",
    "new_point = np.array([[x,y]])\n",
    "\n",
    "X_new = np.vstack([X, new_point])\n",
    "Z = linkage(X_new, method = 'ward')\n",
    "\n",
    "plt.figure(figsize = (8,4))\n",
    "dendrogram(Z)\n",
    "plt.title('Dendrogram')\n",
    "plt.xlabel('Index of points')\n",
    "plt.ylabel('Distance')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Point {x},{y} added to dataset, view dendrogram too see cluster hierarchy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fe3ca51-d472-41b8-9ff6-83aeb3b524eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "X coordinate:  8\n",
      "Y coordinate:  13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,13) is considered outlier\n"
     ]
    }
   ],
   "source": [
    "#Clustering of data points using DBSCAN\n",
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "X = np.array([[1, 2], [1, 4], [1, 0], [4, 2], [4, 4], [4, 0], [10, 2], [10, 4]])\n",
    "\n",
    "dbscan = DBSCAN(eps = 2, min_samples = 2)\n",
    "dbscan.fit(X)\n",
    "\n",
    "x = int(input(\"X coordinate: \"))\n",
    "y = int(input(\"Y coordinate: \"))\n",
    "new_point = np.array([[x,y]])\n",
    "\n",
    "X_new = np.vstack([X,new_point])\n",
    "labels = dbscan.fit_predict(X_new)\n",
    "\n",
    "new_point = labels[-1]\n",
    "if new_point == -1:\n",
    "    print(f\"({x},{y}) is considered outlier\")\n",
    "else:\n",
    "    print(f\"({x},{y}) belongs to cluster {new_point}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e7034-6bc9-4457-80e2-049a9df4b613",
   "metadata": {},
   "source": [
    "## Reinforcement Learning\n",
    "Agent learns to make decisions by interacting with an environment and receiving penalties for actions with the goal of maximising long-term rewards. Eg: Robotics, autonomous vehicles, personalised recommendations.\n",
    "1. Markov Decision Processes (MDPs) - Mathematical framework used in reinforcement learning to model decision-maker, with the goal of maximising cumulative rewards over time.\n",
    "   Application - Robotics, Automated control systems.\n",
    "\n",
    "2. Q-Learning - Agent learns the optimal action to take in each state by using a value function, Q-value, that estimates expected future rewards for each action.\n",
    "   Application - Game AI (Chess, Go), Autonomous vehicles.\n",
    "\n",
    "3. Deep Q-Learning - Extension of Q-Learning which uses deep neural networks to approximate the Q-value function, allowing agents to handle environments with large or continuous state spaces.\n",
    "   Applications - Game AI (AlphaGo), Autonomous vehicles.\n",
    "\n",
    "Evaluation Metrics:\n",
    "1. Cumulative Rewards - Total amount of reward an agent accumulates over an episode or set of episodes; higher the number, better the performance.\n",
    "2. Avg Reward per Episode - Average of total rewards collected over multiple episodes, useful for evaluating performance over many episodes.\n",
    "3. Convergence (Training) Time - Amount of time of number of episodes it takes for agent's performance to converge or stabilise.\n",
    "4. Episode Length - Number of time steps the agent survives in environment before episode ends.\n",
    "5. Exploration vs Exploitation Balance - Proportion of actions taken through exploration (random actions) vs exploitation (learned knowledge)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242ce6df-e3d1-4daf-8f9c-02ef52fa2cef",
   "metadata": {},
   "source": [
    "## Deep Learning\n",
    "A subset of machine learning where artificial neural networks with multiple layers (deep networks) are used to model complex patterns and relationships in data, often for tasks like image recognition, natural language processing, and speech recognition.\n",
    "\n",
    "## What are Neural Networks?\n",
    "Composed of layers of nodes (neurons) that transform input data through weighted connections, allowing the network to learn features and patterns. 5 types:\n",
    "1. Basic Neural Network -\n",
    "   Python Module - from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import Dens\r",
    "2\n",
    "3. Convolutional Neural Networks (CNNs) - Specialized neural networks for processing grid-like data such as images, utilizing convolutional layers to automatically detect spatial hierarchies of features.\n",
    "   Applications - Image classification, object detection, facial recognition.\n",
    "   Python Module from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dens\r",
    "3ns\r",
    "2\n",
    "3. Recurrent Neural Networks (RNNs) - Neural networks designed for sequential data by maintaining a memory of previous inputs, allowing for modeling temporal pat\n",
    "   erns. Applications - Speech recogn\n",
    "   Python Module - from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import SimpleRNN, Dens\r",
    "4ition3\n",
    "4. Long Short-Term Memory (LSTM) - A type of RNN designed to better retain and learn long-term dependencies in sequential data by using gates to control the flow of info\n",
    "   mation. Application - Text gen\n",
    "   Python Module - from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import LSTM, Dens\r",
    "5eration4\n",
    "5. Generative Adversarial Networks (GAN) - A framework with two neural networks (generator and discriminator) where the generator creates fake data and the discriminator evaluates its aut\n",
    "   enticity. Applications - Image g\n",
    "   Python Module - from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import Dense                   \r\n",
    "from tensorflow.keras.optimizers import Adm6\n",
    "e7eration5\n",
    "6. Autoencoders - Neural networks used for unsupervised learning, where the goal is to encode input data into a smaller representation and then recon\n",
    "   truct it. Application - Anomaly \n",
    "   Python Module - from tensorflow.keras.models import Sequential\r",
    "                   \n",
    "from tensorflow.keras.layers import Dese\r\n",
    "detection.\n",
    "\n",
    "Evaluation Metrics:\n",
    "1. Accuracy - Proportion of correct predictions over total predictions.\n",
    "2. Loss Function (Cross-Entropy, MSE) - A measure of error between predicted output and actual output.\n",
    "3. Precision - Ratio of true positive predictions to total positive predictions.\n",
    "4. Recall - Ratio of true positive predictions to total actual positives.\n",
    "5. Training Time - Time taken to train the model on a given dataset.\n",
    "6. Confusion Matrix: A summary table showing the true positives, false positives, true negatives, and false negatives, providing insights into misclassification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "314f2f0d-e0b9-442c-9bd8-9f74765283bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5132 - loss: 0.6951\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6510 - loss: 0.6802 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6514 - loss: 0.6831 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6045 - loss: 0.6789 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7137 - loss: 0.6628 \n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7013 - loss: 0.6586 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7147 - loss: 0.6534 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6870 - loss: 0.6465 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7316 - loss: 0.6378 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7336 - loss: 0.6375 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step\n",
      "[[0.46523935]\n",
      " [0.5771582 ]\n",
      " [0.5132973 ]\n",
      " [0.529539  ]\n",
      " [0.5210597 ]]\n"
     ]
    }
   ],
   "source": [
    "#Basic Neural Network for binary classification \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "X = np.random.rand(100, 10)  # 100 samples, 10 features\n",
    "y = np.random.randint(2, size=(100, 1))  # Binary target\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=10, activation='relu'))  # Input layer\n",
    "model.add(Dense(32, activation='relu')) # Hidden layer\n",
    "model.add(Dense(1, activation='sigmoid')) # Output layer (binary classification)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=10)\n",
    "\n",
    "print(model.predict(X[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a7d27b2-f106-47c5-bff3-ced4adc88991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.1053 - loss: 2.5550\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.1845 - loss: 2.2886\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.1140 - loss: 2.2584\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.2052 - loss: 2.2076  \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4639 - loss: 2.0939\n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5442 - loss: 1.9786\n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.5741 - loss: 1.8338\n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8430 - loss: 1.6850\n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9501 - loss: 1.4823\n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9399 - loss: 1.4092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step\n",
      "[[0.10334595 0.07239339 0.06644128 0.08608638 0.3073517  0.11136482\n",
      "  0.09020814 0.05367239 0.06036087 0.048775  ]\n",
      " [0.10224234 0.06802984 0.09799893 0.08431072 0.2954455  0.11273568\n",
      "  0.07558073 0.05139365 0.06020211 0.05206055]\n",
      " [0.10754878 0.22515953 0.15362526 0.1353362  0.05909051 0.06454622\n",
      "  0.07807185 0.05958314 0.04202411 0.07501452]\n",
      " [0.19823582 0.06211539 0.06570701 0.352709   0.03407181 0.11858374\n",
      "  0.06480863 0.03778511 0.02437392 0.04160955]\n",
      " [0.0945067  0.13203357 0.08971681 0.16328004 0.07044566 0.09561046\n",
      "  0.19971521 0.04132505 0.05744712 0.05591931]]\n"
     ]
    }
   ],
   "source": [
    "#Dummy Image classification using CNN\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "#Dummy Image Data\n",
    "X = np.random.rand(100, 28, 28, 1) # 100 images, 28x28 pixels\n",
    "y = np.random.randint(10, size=(100, 1))  # 10 classes (multi-class) classification\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1))) # Convolution layer\n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) # Pooling layer\n",
    "model.add(Flatten()) # Flattening the output\n",
    "model.add(Dense(128, activation='relu')) # Fully connected layer\n",
    "model.add(Dense(10, activation='softmax')) # Output layer (10 classes)\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=10)\n",
    "\n",
    "print(model.predict(X[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b508fc5-d0b7-4e9c-98cc-a8f1baaed83f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Software\\Anaconda\\New folder\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.5911 - loss: 0.6771\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5833 - loss: 0.6815 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5721 - loss: 0.6811 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5254 - loss: 0.6911 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5064 - loss: 0.6943 \n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5243 - loss: 0.6899 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5646 - loss: 0.6827 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5390 - loss: 0.6870 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5466 - loss: 0.6820 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5054 - loss: 0.6898 \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 218ms/step\n",
      "[[0.5304711]\n",
      " [0.5283775]\n",
      " [0.5184659]\n",
      " [0.5392085]\n",
      " [0.515975 ]]\n"
     ]
    }
   ],
   "source": [
    "# Binary classification of sequential data using RNN\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "X = np.random.rand(100, 5, 1) # 100 sequences, 5 time-steps, 1 feature\n",
    "y = np.random.randint(2, size=(100, 1)) # Binary Classification\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, input_shape=(5, 1), activation='relu')) # RNN layer\n",
    "model.add(Dense(1, activation='sigmoid')) # Output layer (binary classification)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=10)\n",
    "\n",
    "print(model.predict(X[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48226e79-127b-4fe3-9d3b-54e982bac844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.5232 - loss: 0.6929\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4796 - loss: 0.6950 \n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4196 - loss: 0.6965 \n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.4675 - loss: 0.6938 \n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5613 - loss: 0.6927 \n",
      "Epoch 6/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5191 - loss: 0.6934 \n",
      "Epoch 7/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.5710 - loss: 0.6928 \n",
      "Epoch 8/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6107 - loss: 0.6921 \n",
      "Epoch 9/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5460 - loss: 0.6913 \n",
      "Epoch 10/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5453 - loss: 0.6936 \n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x000001C8011E4F40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 271ms/step\n",
      "[[0.49916613]\n",
      " [0.5052677 ]\n",
      " [0.50585526]\n",
      " [0.5016447 ]\n",
      " [0.4925065 ]]\n"
     ]
    }
   ],
   "source": [
    "# Classification of sequential data using LSTM\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "X = np.random.rand(100, 5, 1) # 100 sequences, 5 time-steps, 1 feature\n",
    "y = np.random.randint(2, size=(100, 1)) # Binary classification\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(5, 1))) # LSTM layer\n",
    "model.add(Dense(1, activation='sigmoid')) # Output layer (binary classification)\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=10, batch_size=10)\n",
    "\n",
    "print(model.predict(X[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e9ae59b-a2f3-4ed9-8193-44adc68a216e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step\n",
      "[[0.43095624 0.53886366 0.35650933 0.69781244 0.5504346  0.3822705\n",
      "  0.53944355 0.4793987  0.47923282 0.4215201  0.65135676 0.59085\n",
      "  0.48593298 0.475907   0.5171728  0.48171338 0.35843784 0.31997216\n",
      "  0.69688797 0.36894634 0.33220202 0.49166542 0.56047964 0.3775352\n",
      "  0.57308567 0.6003705  0.43047673 0.36440295 0.50423783 0.51383305\n",
      "  0.428591   0.4300682  0.44608623 0.49616605 0.5143464  0.5036639\n",
      "  0.4898072  0.5111284  0.42604607 0.46032557 0.53854454 0.4539977\n",
      "  0.3490378  0.6161779  0.5983516  0.611071   0.44836804 0.37384084\n",
      "  0.41797468 0.39326808 0.41483942 0.4328452  0.4716974  0.30386588\n",
      "  0.45753783 0.53377044 0.4760778  0.6584148  0.47750133 0.53021145\n",
      "  0.5028408  0.60401905 0.38561478 0.36366338 0.5108104  0.43536422\n",
      "  0.50506264 0.44537464 0.4854247  0.36308917 0.5694325  0.45890847\n",
      "  0.47466192 0.6812031  0.49136105 0.58276355 0.2241903  0.5222908\n",
      "  0.51818466 0.37235555 0.5099312  0.39990118 0.5499039  0.49659747\n",
      "  0.55376035 0.3953551  0.49220592 0.45859617 0.5203494  0.53987443\n",
      "  0.40109357 0.5828141  0.39862242 0.5060339  0.2942051  0.31725815\n",
      "  0.5599898  0.53666544 0.6090977  0.36518255 0.4282909  0.5765673\n",
      "  0.59740835 0.36987588 0.40825203 0.4228313  0.40208766 0.5340934\n",
      "  0.53272957 0.45100695 0.3783042  0.46522135 0.6063297  0.51572406\n",
      "  0.538523   0.3673052  0.5736147  0.56754166 0.51607823 0.44955888\n",
      "  0.49804172 0.3319969  0.36019993 0.510345   0.3733991  0.56398344\n",
      "  0.51756775 0.44918847 0.3707618  0.37912542 0.5203626  0.5285976\n",
      "  0.6123181  0.49499083 0.6185732  0.4901359  0.47030318 0.36192858\n",
      "  0.4866063  0.65990597 0.48785484 0.48338392 0.64250124 0.45233026\n",
      "  0.4546216  0.6563238  0.43546873 0.32904464 0.62259734 0.40600976\n",
      "  0.45023254 0.49658737 0.48675668 0.4217079  0.7053224  0.3438784\n",
      "  0.5476648  0.57280266 0.49383482 0.5722688  0.40795842 0.41537997\n",
      "  0.5329963  0.46803194 0.46578246 0.6435656  0.50142455 0.48096108\n",
      "  0.37613997 0.5208693  0.43042383 0.56194043 0.45450687 0.43682438\n",
      "  0.5200852  0.39525598 0.66457856 0.51182175 0.6161691  0.6203365\n",
      "  0.37820542 0.580894   0.56335616 0.5360919  0.5273351  0.5087466\n",
      "  0.5789475  0.536342   0.5949778  0.35591945 0.51423526 0.47233012\n",
      "  0.36364818 0.47054416 0.44753617 0.5538201  0.5867709  0.53086525\n",
      "  0.44952816 0.59579474 0.565552   0.6095977  0.5709393  0.5220123\n",
      "  0.56571674 0.43948153 0.61077225 0.44889817 0.49909294 0.63667715\n",
      "  0.3761116  0.33630887 0.58018315 0.4371071  0.69471174 0.6039853\n",
      "  0.60460556 0.43830338 0.66133285 0.6756699  0.48173764 0.55267596\n",
      "  0.60943544 0.50504464 0.3661491  0.5512081  0.5045626  0.47482514\n",
      "  0.46908    0.47889182 0.49611044 0.65994865 0.47699606 0.5741634\n",
      "  0.5297925  0.65156215 0.49745855 0.5230645  0.64949214 0.47825366\n",
      "  0.6317396  0.5904518  0.46710908 0.522237   0.62783325 0.5268339\n",
      "  0.65987563 0.5256201  0.44324303 0.5181978  0.59872234 0.4394544\n",
      "  0.35232803 0.3352038  0.6386708  0.6418909  0.47402564 0.4908843\n",
      "  0.43848202 0.48917308 0.4044895  0.46739092 0.5217361  0.5795354\n",
      "  0.5062202  0.41178983 0.4921585  0.56890965 0.5349106  0.57013685\n",
      "  0.43856025 0.45863843 0.3593179  0.5118462  0.5638504  0.5924336\n",
      "  0.6142593  0.3409125  0.5006945  0.5921247  0.49114305 0.5281106\n",
      "  0.6625823  0.55756587 0.37407953 0.41905734 0.32458243 0.3672566\n",
      "  0.42446473 0.4390738  0.6038828  0.5461514  0.5423415  0.49920493\n",
      "  0.5595348  0.57541394 0.5948602  0.5354391  0.456419   0.52645814\n",
      "  0.64884126 0.5203695  0.49873543 0.4857028  0.55607164 0.4920992\n",
      "  0.5407469  0.2667092  0.55634916 0.48386934 0.4813114  0.5037968\n",
      "  0.5489109  0.56316113 0.5494839  0.49640203 0.36524078 0.6109374\n",
      "  0.52751875 0.32940918 0.32061082 0.6247256  0.5456425  0.5931641\n",
      "  0.28097758 0.5295491  0.4868065  0.47329298 0.51067126 0.5666275\n",
      "  0.49558333 0.5555247  0.35602003 0.5543245  0.6795934  0.47358498\n",
      "  0.4747828  0.50800455 0.58796287 0.47808388 0.50622594 0.4548569\n",
      "  0.40645388 0.44554093 0.5181967  0.4823152  0.49374136 0.5656755\n",
      "  0.5218888  0.4383351  0.4887349  0.42905793 0.45114416 0.52695155\n",
      "  0.35148105 0.51057243 0.592309   0.50961566 0.48784184 0.6050161\n",
      "  0.45128652 0.47142014 0.43475983 0.49032834 0.52673155 0.498182\n",
      "  0.44330493 0.50472856 0.47913837 0.51791537 0.5004302  0.4766926\n",
      "  0.3619006  0.4333366  0.39097038 0.5164219  0.429578   0.47158843\n",
      "  0.49856773 0.6777189  0.38447648 0.5142381  0.48080894 0.45924404\n",
      "  0.49281114 0.6330111  0.27910328 0.63137615 0.59310627 0.5641674\n",
      "  0.5225193  0.5979353  0.46568534 0.41481364 0.70511746 0.61393344\n",
      "  0.5426645  0.5757592  0.5029979  0.37944642 0.48333335 0.45152375\n",
      "  0.5706161  0.5408758  0.3438014  0.5969043  0.39980036 0.5029155\n",
      "  0.59620696 0.36614084 0.6034905  0.43647915 0.58523715 0.49745083\n",
      "  0.5555661  0.63067794 0.59291553 0.42041835 0.68184507 0.5472015\n",
      "  0.51537144 0.55098295 0.5654696  0.45746943 0.4262955  0.39625874\n",
      "  0.6885506  0.70308924 0.4712873  0.5353043  0.6128812  0.42828146\n",
      "  0.46260917 0.6236532  0.45408735 0.60202765 0.59061193 0.51820874\n",
      "  0.56379133 0.5666101  0.51964146 0.40535688 0.50494456 0.44889578\n",
      "  0.46886402 0.54494125 0.4609521  0.38673577 0.6410962  0.6149047\n",
      "  0.67292017 0.58148384 0.5273033  0.45864165 0.6309531  0.52256304\n",
      "  0.47811863 0.699721   0.3207223  0.7623921  0.4903905  0.5702143\n",
      "  0.49939713 0.4998299  0.4475251  0.4963157  0.35255635 0.55416185\n",
      "  0.43720886 0.59354055 0.4192786  0.42599353 0.55068505 0.32098296\n",
      "  0.5314948  0.5385337  0.40836105 0.56003547 0.6662734  0.4143437\n",
      "  0.59883714 0.47720456 0.46485713 0.47175068 0.39211616 0.6063756\n",
      "  0.5190333  0.4635917  0.4637726  0.39438823 0.36130175 0.63961375\n",
      "  0.5829108  0.40549016 0.2839366  0.45740452 0.60359925 0.42349082\n",
      "  0.43433854 0.5248536  0.44386536 0.6416987  0.3494124  0.6997297\n",
      "  0.45151454 0.5265574  0.4472118  0.5757089  0.55618304 0.4632343\n",
      "  0.62673664 0.4962774  0.2803907  0.51426685 0.37117386 0.44005898\n",
      "  0.49378943 0.355791   0.62303126 0.5855064  0.4921368  0.50175524\n",
      "  0.42957613 0.51910925 0.43479052 0.5112978  0.52269226 0.41595992\n",
      "  0.39892685 0.5601789  0.5703194  0.5635358  0.34114605 0.45521683\n",
      "  0.64834213 0.46048707 0.4043509  0.46144497 0.5418513  0.37806776\n",
      "  0.4100907  0.5282109  0.59629124 0.22100332 0.43581915 0.55908597\n",
      "  0.4547092  0.30249205 0.40632904 0.2978847  0.3975435  0.3698786\n",
      "  0.6121805  0.2341084  0.36804953 0.5912687  0.3283267  0.57651305\n",
      "  0.50849074 0.48987606 0.66940415 0.45947814 0.4885502  0.5282141\n",
      "  0.6198243  0.4641684  0.34152865 0.6414102  0.41648522 0.46371028\n",
      "  0.53316736 0.5391536  0.5999676  0.49385962 0.41559258 0.5510622\n",
      "  0.59901655 0.30613318 0.50425506 0.6044776  0.40113562 0.52732754\n",
      "  0.5547253  0.4584516  0.6036962  0.59959555 0.52573884 0.34247494\n",
      "  0.5932581  0.62801635 0.34432107 0.5769856  0.4491152  0.4635674\n",
      "  0.38861516 0.43338022 0.49743995 0.4271821  0.49713618 0.5186721\n",
      "  0.38431492 0.55926704 0.48368433 0.46008042 0.60966706 0.39386332\n",
      "  0.4997639  0.41748387 0.5099014  0.48800644 0.4525879  0.6308955\n",
      "  0.58312166 0.46956214 0.44577047 0.57451016 0.38585287 0.5644316\n",
      "  0.6954793  0.41261944 0.4287759  0.42915606 0.5656959  0.39023432\n",
      "  0.37261945 0.3985549  0.50784564 0.5565572  0.32016197 0.45315182\n",
      "  0.5120591  0.62879205 0.47302166 0.5564376  0.5338069  0.4125854\n",
      "  0.44848382 0.37268373 0.50472856 0.49360615 0.65134645 0.56854624\n",
      "  0.4639224  0.41343907 0.46956038 0.6140262  0.5619198  0.46182644\n",
      "  0.5722108  0.6387858  0.49077243 0.3884631  0.38881284 0.44224203\n",
      "  0.54173905 0.5493677  0.63738626 0.49594843 0.3524825  0.3314468\n",
      "  0.55056524 0.573117   0.5666417  0.4262215  0.56856257 0.31638473\n",
      "  0.62879956 0.5109725  0.4723409  0.42804307 0.3686918  0.5481688\n",
      "  0.34747696 0.5511404  0.5978681  0.5342101  0.5148535  0.49646807\n",
      "  0.6259412  0.61682975 0.48435685 0.33599776 0.399224   0.5731144\n",
      "  0.5278723  0.5103151  0.5694573  0.5172943  0.50707734 0.46908912\n",
      "  0.55923796 0.5534766  0.42323595 0.5134487  0.4304071  0.56043863\n",
      "  0.672928   0.4215269  0.44009298 0.47841606 0.5270623  0.6022286\n",
      "  0.4737688  0.6306213  0.513255   0.31353498 0.4371632  0.48825398\n",
      "  0.3741935  0.533133   0.5382904  0.46872693 0.4438894  0.6301328\n",
      "  0.55792594 0.5451253  0.45507553 0.6182682  0.5478394  0.33467945\n",
      "  0.5340957  0.5521836  0.54349434 0.44775397 0.46044886 0.5336174\n",
      "  0.48259795 0.5085046  0.3985793  0.41107005 0.543074   0.5604894\n",
      "  0.55913997 0.51514673 0.61793697 0.5208862  0.5163372  0.62749434\n",
      "  0.34000692 0.48515198 0.43046334 0.3365073  0.56677306 0.33659115\n",
      "  0.57728595 0.5414095  0.52654755 0.4719958  0.5351157  0.4544933\n",
      "  0.6073531  0.50905854 0.6064768  0.5644268  0.65288556 0.26749238\n",
      "  0.45344266 0.27447668 0.48109156 0.40280727 0.498729   0.41992995\n",
      "  0.45027938 0.5267445  0.3382635  0.5609668  0.4461827  0.5036783\n",
      "  0.5318247  0.35578665 0.36238778 0.47370884 0.5827527  0.54533803\n",
      "  0.6076993  0.6001822  0.4733328  0.33222455 0.6047853  0.56980234\n",
      "  0.55666316 0.58565056 0.4891494  0.623603  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_generator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=100))\n",
    "    model.add(Dense(784, activation='sigmoid'))  # Assuming 28x28 image (784 pixels)\n",
    "    return model\n",
    "def build_discriminator():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_dim=784))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "generator = build_generator()\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "gan = Sequential([generator, discriminator])\n",
    "gan.compile(optimizer=Adam(), loss='binary_crossentropy')\n",
    "\n",
    "noise = np.random.randn(10, 100)\n",
    "fake_images = generator.predict(noise)\n",
    "\n",
    "print(fake_images[:1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc69fd4-517b-462f-88b8-43265d158b4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
